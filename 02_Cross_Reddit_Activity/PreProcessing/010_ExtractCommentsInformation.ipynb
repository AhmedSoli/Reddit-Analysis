{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import bz2\n",
    "import pickle \n",
    "import json\n",
    "import os\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function for extracting comment information for a specific month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments_information(file_path):\n",
    "    print(file_path[-8:-3])\n",
    "    \n",
    "    subreddits = {}\n",
    "    commentators = {}\n",
    "    \n",
    "    if '.bz2' in file_path:\n",
    "        _open = bz2.open\n",
    "    else:\n",
    "        _open = lzma.open\n",
    "    \n",
    "    with _open(file_path,'rt') as comments_data:\n",
    "        for i,comment in enumerate(comments_data):\n",
    "            comment = json.loads(comment)\n",
    "            if 'subreddit' in comment:\n",
    "                if comment['subreddit'] not in subreddits:\n",
    "                    subreddits[comment['subreddit']] = {\n",
    "                        'comments': {},\n",
    "                        'commentators': set()\n",
    "                    }\n",
    "                if comment['author'] not in subreddits[comment['subreddit']]['comments']:\n",
    "                    subreddits[comment['subreddit']]['comments'][comment['author']] = {\n",
    "                        'timestamps': [],\n",
    "                        'votes': []\n",
    "                    }\n",
    "                    \n",
    "                subreddits[comment['subreddit']]['comments'][comment['author']]['timestamps'].append(comment['created_utc'])\n",
    "                subreddits[comment['subreddit']]['comments'][comment['author']]['votes'].append(comment['score'])\n",
    "                subreddits[comment['subreddit']]['commentators'].add(comment['author'])\n",
    "                \n",
    "                if comment['author'] not in commentators:\n",
    "                    commentators[comment['author']] = {\n",
    "                        'timestamps': [],\n",
    "                        'votes': []\n",
    "                    }\n",
    "                    \n",
    "                commentators[comment['author']]['timestamps'].append(comment['created_utc'])\n",
    "                commentators[comment['author']]['votes'].append(comment['score'])\n",
    "                \n",
    "            if i % 1000000 == 0:\n",
    "                print(file_path,i)\n",
    "\n",
    "        #save the subreddit dict in a file\n",
    "        pickle_out = open(\"../../Results/comments_\" + file_path[-8:-3] + \".pickle\",\"wb\")\n",
    "        pickle.dump(subreddits, pickle_out)\n",
    "        pickle_out.close()\n",
    "        \n",
    "        #save the subreddit dict in a file\n",
    "        pickle_out = open(\"../../Results/commentators_\" + file_path[-8:-3] + \".pickle\",\"wb\")\n",
    "        pickle.dump(commentators, pickle_out)\n",
    "        pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify all files containing information about comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path storing the data regarding the comments\n",
    "folder = '/home/data/reddit/comments/'\n",
    "files = os.listdir(folder)\n",
    "required_files = []\n",
    "\n",
    "for key,file in enumerate(files):\n",
    "    if file[3:7] >= \"2016\" and ('bz2' in file or 'xz' in file):\n",
    "        required_files.append(folder + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the calculations parallelised over the number of cores available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = multiprocessing.Pool(len(required_files))\n",
    "print(p.map(extract_comments_information, required_files))\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = {}\n",
    "commentators = {}\n",
    "\n",
    "for file in required_files:\n",
    "    commentators_temp = pickle.load(open(\"Results/commentators_\" + file + \".pickle.gz\",\"rb\"))\n",
    "    subreddits_temp = pickle.load(open(\"Results/comments_\" + file + \".pickle.gz\",\"rb\"))\n",
    "    \n",
    "    for commentator in commentators_temp:\n",
    "        \n",
    "        if commentator not in commentators:\n",
    "            commentators[commentator] = {\n",
    "                        'timestamps': [],\n",
    "                        'votes': []\n",
    "                    }\n",
    "        commentators[commentator]['timestamps'].extend(\n",
    "            commentators_temp[commentator]['timestamps']\n",
    "        )\n",
    "        commentators[commentator]['votes'].extend(\n",
    "            commentators_temp[commentator]['votes']\n",
    "        )\n",
    "        \n",
    "    for subreddit in subreddits_temp:\n",
    "        \n",
    "        if subreddit not in subreddits:\n",
    "            subreddits[subreddit] = {\n",
    "                'comments': {},\n",
    "                'commentators': set()\n",
    "            }\n",
    "        \n",
    "        subreddits[subreddit]['commentators'].update(\n",
    "            subreddits_temp[subreddit]['commentators']\n",
    "        )\n",
    "        \n",
    "        for commentator in subreddits_temp[subreddit]['comments']:\n",
    "            \n",
    "            if commentator not in subreddits[subreddit]['comments']:\n",
    "                subreddits[subreddit]['comments'][commentator] = {\n",
    "                    'timestamps': [],\n",
    "                    'votes': []\n",
    "                }\n",
    "                \n",
    "            subreddits[subreddit]['comments'][commentator]['timestamps'].extend(\n",
    "                subreddits_temp[subreddit]['comments'][commentator]['timestamps']\n",
    "            )\n",
    "            \n",
    "            subreddits[subreddit]['comments'][commentator]['votes'].extend(\n",
    "                subreddits_temp[subreddit]['comments'][commentator]['votes']\n",
    "            )\n",
    "            \n",
    "    print(len(commentators))\n",
    "    print(len(subreddits['politics']['commentators']))\n",
    "                        \n",
    "pickle_out = open(\"../../Results/commentators.pickle\",\"wb\")\n",
    "pickle.dump(commentators, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"../../Results/comments.pickle\",\"wb\")\n",
    "pickle.dump(subreddits, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
