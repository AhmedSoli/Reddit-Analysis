{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import lzma\n",
    "import json\n",
    "import pickle \n",
    "import os\n",
    "import multiprocessing\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/data/reddit/submissions/RS_2017-12.xz',\n",
       " '/home/data/reddit/submissions/RS_2018-01.xz',\n",
       " '/home/data/reddit/submissions/RS_2018-02.xz',\n",
       " '/home/data/reddit/submissions/RS_2018-03.xz',\n",
       " '/home/data/reddit/submissions/RS_2018-04.xz',\n",
       " '/home/data/reddit/submissions/RS_2018-05.xz',\n",
       " '/home/data/reddit/submissions/RS_2018-06.xz',\n",
       " '/home/data/reddit/submissions/RS_2018-07.xz',\n",
       " '/home/data/reddit/submissions/RS_2018-08.xz']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def worker(file_path):\n",
    "    print(file_path[-8:-3])\n",
    "    \n",
    "    subreddits = {}\n",
    "    submissioners = {}\n",
    "    \n",
    "    if '.bz2' in file_path:\n",
    "        _open = bz2.open\n",
    "    else:\n",
    "        _open = lzma.open\n",
    "    \n",
    "    with _open(file_path,'rt') as submissions_data:\n",
    "        for i,submission in enumerate(submissions_data):\n",
    "            submission = json.loads(submission)\n",
    "            if 'subreddit' in submission:\n",
    "                if submission['subreddit'] not in subreddits:\n",
    "                    subreddits[submission['subreddit']] = {\n",
    "                        'submissions': {},\n",
    "                        'submissioners': set()\n",
    "                    }\n",
    "                if submission['author'] not in subreddits[submission['subreddit']]['submissions']:\n",
    "                    subreddits[submission['subreddit']]['submissions'][submission['author']] = {\n",
    "                        'timestamps': [],\n",
    "                        'votes': [],\n",
    "                        'comments': []\n",
    "                    }\n",
    "                    \n",
    "                subreddits[submission['subreddit']]['submissions'][submission['author']]['timestamps'].append(submission['created_utc'])\n",
    "                subreddits[submission['subreddit']]['submissions'][submission['author']]['votes'].append(submission['score'])\n",
    "                subreddits[submission['subreddit']]['submissions'][submission['author']]['comments'].append(submission['num_comments'])\n",
    "                subreddits[submission['subreddit']]['submissioners'].add(submission['author'])\n",
    "                \n",
    "                if submission['author'] not in submissioners:\n",
    "                    submissioners[submission['author']] = {\n",
    "                        'timestamps': [],\n",
    "                        'votes': [],\n",
    "                        'comments': []\n",
    "                    }\n",
    "                    \n",
    "                submissioners[submission['author']]['timestamps'].append(submission['created_utc'])\n",
    "                submissioners[submission['author']]['votes'].append(submission['score'])\n",
    "                submissioners[submission['author']]['comments'].append(submission['num_comments'])\n",
    "                \n",
    "            if i % 1000000 == 0:\n",
    "                print(file_path,i)\n",
    "\n",
    "        #save the subreddit dict in a file\n",
    "        pickle_out = open(\"Results/submissions_\" + file_path[-8:-3] + \".pickle\",\"wb\")\n",
    "        pickle.dump(subreddits, pickle_out)\n",
    "        pickle_out.close()\n",
    "        \n",
    "        #save the subreddit dict in a file\n",
    "        pickle_out = open(\"Results/submissioners_\" + file_path[-8:-3] + \".pickle\",\"wb\")\n",
    "        pickle.dump(submissioners, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "# path storing the data regarding the submissions\n",
    "folder = '/home/data/reddit/submissions/'\n",
    "files = os.listdir(folder)\n",
    "required_files = []\n",
    "\n",
    "\n",
    "for key,file in enumerate(files):\n",
    "    if \"v2\" not in file  and \"2017-07\" not in file and \"2017-11\" not in file and file[3:7] >= \"2017\" and ('xz' in file):\n",
    "        required_files.append(folder + file)\n",
    "sorted(required_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18-05\n",
      "18-06\n",
      "17-12\n",
      "18-04\n",
      "18-02\n",
      "18-07\n",
      "18-08\n",
      "18-03\n",
      "18-01\n",
      "/home/data/reddit/submissions/RS_2017-12.xz 0\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 0\n",
      "/home/data/reddit/submissions/RS_2018-02.xz 0\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 0\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 0\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 0\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 0\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 0\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 0\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 1000000\n",
      "/home/data/reddit/submissions/RS_2018-02.xz 1000000\n",
      "/home/data/reddit/submissions/RS_2017-12.xz 1000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 1000000\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 1000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 1000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 1000000\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 1000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 1000000\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 2000000\n",
      "/home/data/reddit/submissions/RS_2017-12.xz 2000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 2000000\n",
      "/home/data/reddit/submissions/RS_2018-02.xz 2000000\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 2000000\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 2000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 2000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 2000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 2000000\n",
      "/home/data/reddit/submissions/RS_2017-12.xz 3000000\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 3000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 3000000\n",
      "/home/data/reddit/submissions/RS_2018-02.xz 3000000\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 3000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 3000000\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 3000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 3000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 3000000\n",
      "/home/data/reddit/submissions/RS_2017-12.xz 4000000\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 4000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 4000000\n",
      "/home/data/reddit/submissions/RS_2018-02.xz 4000000\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 4000000\n",
      "/home/data/reddit/submissions/RS_2017-12.xz 5000000\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 5000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 4000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 4000000\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 4000000\n",
      "/home/data/reddit/submissions/RS_2018-02.xz 5000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 5000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 4000000\n",
      "/home/data/reddit/submissions/RS_2017-12.xz 6000000\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 6000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 5000000\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 5000000\n",
      "/home/data/reddit/submissions/RS_2018-02.xz 6000000\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 5000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 6000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 5000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 5000000\n",
      "/home/data/reddit/submissions/RS_2017-12.xz 7000000\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 7000000\n",
      "/home/data/reddit/submissions/RS_2018-02.xz 7000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 7000000\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 6000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 6000000\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 6000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 6000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 6000000\n",
      "/home/data/reddit/submissions/RS_2017-12.xz 8000000\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 8000000\n",
      "/home/data/reddit/submissions/RS_2018-02.xz 8000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 8000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 7000000\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 7000000\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 7000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 7000000\n",
      "/home/data/reddit/submissions/RS_2017-12.xz 9000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 7000000\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 9000000\n",
      "/home/data/reddit/submissions/RS_2018-02.xz 9000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 9000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 8000000\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 8000000\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 8000000\n",
      "/home/data/reddit/submissions/RS_2017-12.xz 10000000\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 10000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 8000000\n",
      "/home/data/reddit/submissions/RS_2018-02.xz 10000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 8000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 10000000\n",
      "/home/data/reddit/submissions/RS_2018-01.xz 11000000\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 9000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 9000000\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 9000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 9000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 11000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 9000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 10000000\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 10000000\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 10000000\n",
      "/home/data/reddit/submissions/RS_2018-03.xz 12000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 10000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 10000000\n",
      "/home/data/reddit/submissions/RS_2018-06.xz 11000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 11000000\n",
      "/home/data/reddit/submissions/RS_2018-04.xz 11000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 11000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 11000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 12000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 12000000\n",
      "/home/data/reddit/submissions/RS_2018-05.xz 12000000\n",
      "/home/data/reddit/submissions/RS_2018-07.xz 13000000\n",
      "/home/data/reddit/submissions/RS_2018-08.xz 13000000\n",
      "[None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "# run the calculation\n",
    "p = multiprocessing.Pool(len(required_files))\n",
    "print(p.map(worker, required_files))\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16-01',\n",
       " '16-02',\n",
       " '16-03',\n",
       " '16-04',\n",
       " '16-05',\n",
       " '16-06',\n",
       " '16-07',\n",
       " '16-08',\n",
       " '16-09',\n",
       " '16-10',\n",
       " '16-11',\n",
       " '16-12',\n",
       " '17-01',\n",
       " '17-02',\n",
       " '17-03',\n",
       " '17-04',\n",
       " '17-05',\n",
       " '17-06',\n",
       " '17-07',\n",
       " '17-08',\n",
       " '17-09',\n",
       " '17-10',\n",
       " '17-11',\n",
       " '17-12',\n",
       " '18-01',\n",
       " '18-02',\n",
       " '18-03',\n",
       " '18-04',\n",
       " '18-05',\n",
       " '18-06',\n",
       " '18-07',\n",
       " '18-08']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_files = []\n",
    "for file in os.listdir('Results'):\n",
    "    if 'submissions' in file:\n",
    "        required_files.append(file[-15:-10])\n",
    "sorted(required_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2365246\n",
      "6416\n",
      "3866315\n",
      "16154\n",
      "5037508\n",
      "19591\n",
      "5976153\n",
      "25557\n",
      "6630617\n",
      "30256\n",
      "7593964\n",
      "34842\n",
      "8219978\n",
      "39411\n",
      "8695993\n",
      "43422\n",
      "9477313\n",
      "47645\n",
      "9914433\n",
      "53767\n",
      "10982563\n",
      "59552\n",
      "11981217\n",
      "62801\n",
      "12411867\n",
      "66204\n",
      "12968438\n",
      "69731\n",
      "13471276\n",
      "74470\n",
      "14090585\n",
      "76993\n",
      "14554455\n",
      "81474\n",
      "15001483\n",
      "84238\n",
      "15560849\n",
      "87629\n",
      "15888766\n",
      "90825\n",
      "16184949\n",
      "96778\n",
      "16580826\n",
      "100722\n",
      "16897121\n",
      "103169\n",
      "17329084\n",
      "105783\n",
      "17662637\n",
      "108245\n",
      "18028376\n",
      "111141\n",
      "18346810\n",
      "115183\n",
      "18842216\n",
      "117862\n",
      "19265420\n",
      "119889\n",
      "19587750\n",
      "121833\n",
      "19869314\n",
      "124248\n",
      "20226667\n",
      "127227\n"
     ]
    }
   ],
   "source": [
    "subreddits = {}\n",
    "submissioners = {}\n",
    "\n",
    "for file in required_files:\n",
    "    submissioners_temp = pickle.load(gzip.open(\"Results/submissioners_\" + file + \".pickle.gz\",\"rb\"))\n",
    "    subreddits_temp = pickle.load(gzip.open(\"Results/submissions_\" + file + \".pickle.gz\",\"rb\"))\n",
    "    \n",
    "    for submissioner in submissioners_temp:\n",
    "        \n",
    "        if submissioner not in submissioners:\n",
    "            submissioners[submissioner] = {\n",
    "                'timestamps': [],\n",
    "                'votes': [],\n",
    "                'comments': []\n",
    "                        \n",
    "            }\n",
    "            \n",
    "        submissioners[submissioner]['timestamps'].extend(\n",
    "            submissioners_temp[submissioner]['timestamps']\n",
    "        )\n",
    "        submissioners[submissioner]['votes'].extend(\n",
    "            submissioners_temp[submissioner]['votes']\n",
    "        )\n",
    "        submissioners[submissioner]['comments'].extend(\n",
    "            submissioners_temp[submissioner]['comments']\n",
    "        )\n",
    "        \n",
    "    for subreddit in subreddits_temp:\n",
    "        \n",
    "        if subreddit not in subreddits:\n",
    "            subreddits[subreddit] = {\n",
    "                'submissions': {},\n",
    "                'submissioners': set()\n",
    "            }\n",
    "        \n",
    "        subreddits[subreddit]['submissioners'].update(\n",
    "            subreddits_temp[subreddit]['submissioners']\n",
    "        )\n",
    "        \n",
    "        for submissioner in subreddits_temp[subreddit]['submissions']:\n",
    "            \n",
    "            if submissioner not in subreddits[subreddit]['submissions']:\n",
    "                subreddits[subreddit]['submissions'][submissioner] = {\n",
    "                    'timestamps': [],\n",
    "                    'votes': [],\n",
    "                    'comments': []\n",
    "                }\n",
    "                \n",
    "            subreddits[subreddit]['submissions'][submissioner]['timestamps'].extend(\n",
    "                subreddits_temp[subreddit]['submissions'][submissioner]['timestamps']\n",
    "            )\n",
    "            \n",
    "            subreddits[subreddit]['submissions'][submissioner]['votes'].extend(\n",
    "                subreddits_temp[subreddit]['submissions'][submissioner]['votes']\n",
    "            )\n",
    "            \n",
    "            subreddits[subreddit]['submissions'][submissioner]['comments'].extend(\n",
    "                subreddits_temp[subreddit]['submissions'][submissioner]['comments']\n",
    "            )\n",
    "    print(len(submissioners))\n",
    "    print(len(subreddits['politics']['submissioners']))\n",
    "\n",
    "                        \n",
    "pickle_out = open(\"Results/submissioners.pickle\",\"wb\")\n",
    "pickle.dump(submissioners, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Results/submissions.pickle\",\"wb\")\n",
    "pickle.dump(subreddits, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
